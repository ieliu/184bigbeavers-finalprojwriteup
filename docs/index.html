

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        body {
            background-color: white;
            padding: 100px;
            width: 1000px;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: 'Open Sans', sans-serif;
            color: #121212;
        }
        h1, h2, h3, h4 {
            font-family: 'Source Sans Pro', sans-serif;
        }
        kbd {
            color: #121212;
        }
    </style>
    <title>CS184 Big Beavers Final Proj
    </title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Final Project: Tattoo Style Rendering</h1>
<h2 align="middle">Big Beavers: Jojo Chen, Michelle Chen, Isabelle Liu, and Nicholas Cheng</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://ieliu.github.io/184bigbeavers-finalprojwriteup/">https://ieliu.github.io/184bigbeavers-finalprojwriteup/</a></h2>



<!--<div align="center">-->
<!--  <table style="width=100%">-->
<!--      <tr>-->
<!--          <td align="middle">-->
<!--          <img src="images/example_image.png" width="480px" />-->
<!--          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>-->
<!--      </tr>-->
<!--  </table>-->
<!--</div>-->

<!--<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>-->
<!--<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> -->
<!--<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>-->


<!--<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>-->
<!--<ul>-->
<!--<li>Your main report page should be called index.html.</li>-->
<!--<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>-->
<!--<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>-->
<!--Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>-->
<!--<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>-->
<!--<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>-->
<!--<li>And again, test your website on the instructional machines early!</li>-->
<!--</ul>-->


<!--<p>Here is an example of how to include a simple formula:</p>-->
<!--<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>-->
<!--<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>-->

<!--<div>-->

<h2 align="middle">Abstract</h2>
<h3> A paragraph summary of the entire project. </h3>
<p>
    In this project, we explored non-photorealistic rendering to create a tool for tattoo artists to easily generate designs in different tattoo styles. Our inspiration for this project came from the show Ink Masters, which our team members are all a fan of. On the show, we saw how difficult it was for tattoo artists to create art in many different art styles to please their clients. We hoped that our tool could help them easily create stencils in varying styles. By altering how light is rendered in a typical photorealistic manner we have learned in class, we created line art, stick & poke, American traditional, and chrome tattoo style renderings. 
</p>
<br>

<h2 align="middle">Technical approach</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
    A 1-2 page summary of your technical approach, techniques used, algorithms implemented, etc. (use references to papers or other resources for further detail). Highlight how your approach varied from the references used (did you implement a subset, or did you change or enhance anything), the unique decisions you made and why.
</h3>
<h3>A description of problems encountered and how you tackled them.</h3>
<h3>A description of lessons learned.</h3>

<p align="middle"><b>Line Art Style</b></p>
<p>To recreate line art, we needed to have lines emphasizing each of the curves and edges of our models. After researching multiple possible ways, we landed on using an edge detection filter as the simplest way to implement into our existing project 3 code. We decided to use the Sobel Edge Detection technique. Essentially how the filtering works is that we can create two kernel matrices that act as masks for detecting horizontal and vertical edges.  For our implementation, we created a helper function Raytraced_Renderer::is_edge that basically applied the Sobel operator to the pixel, and returned whether that pixel was on an edge or not. Then, we just modified our Raytraced_Renderer::raytrace_tile method to call our new helper function!</p>

<div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/sobelmatrices.png" align="middle" width="500vw" />
                    <figcaption>G_x and G_y matrices</figcaption>
                </td>
        </table>
</div>
<p>Each of the kernels are applied to the image, and we can then combine the outputs to find the absolute magnitude of the gradient at each point in our image. We calculate the gradient magnitude with |G| = sqrt(Gx + Gy). After we’ve calculated all of our gradients, we apply a threshold value that allows us to differentiate pixels that are part of an edge and those that are not. We played around with the value of the threshold a lot, seeing whichever would give us the best results and we found that a higher threshold reduced the noise in our image and produced more precise edges. </p>
<p>One big problem that we encountered was with our threshold value. At first, we didn’t realize that our implementation would only produce good results with a very high threshold value, so we were encountering very grainy results or even seeing 3 bunny outlines at some point. After increasing our threshold value, everything became a bit smoother and actually fit our bunny model. </p>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td>
                <img src="images/oopsiesoutline.png" align="middle" width="400vw" />
                <figcaption>Our first outline attempt!</figcaption>
            </td>
    </table>
</div>

<p>Another issue that we encountered is the way that the colors are stored in the data model of project 3, which is what we mainly built our project off of. Usually, colors are stored as rgb triplets. However, for this portion we were working with the 2D image buffers in the raytrace renderer, where colors were instead stored as hexadecimals. In order to be able to work with the colors as flexibly as we wanted to, we reversed the way the rgb values were stored in the image buffer using some bit twiddling. Since our research showed that Sobel worked best with grayscale values, we again averaged the values we retrieved and used the grayscale value in our gradient calculations. Unfortunately, this means that our edge detection isn’t great for detecting edges between colors that contrasted but shared similar grayscale values. </p>

<p align="middle"><b>Stick and poke</b></p>
<p>Stick and poke tattooing seeks to create an image with a collection of dots of varying density to mimic shading. Images are generally grayscale and may or may not have an outline. On a high level, to create this effect, we first determined a grayscale value for each pixel. Since the density of dots create the values in stick and poke tattoos, we mimicked the effect by coloring each pixel either black or white according to a probability generated by their grayscale value. Therefore, pixels with a lower grayscale value (closer to white) have a higher probability of getting filled in with white and vice versa.  </p>
<p> More specifically, we altered the PathTracer::raytrace_pixel() function. After generating the average value of the samples taken, we took the average of the rgb values((r+g+b)/3). This generates a grayscale equivalent using the average method described here. If we set each of r, g, and b to this average value, we get a grayscale equivalent of our original color (rgb(avg_val, avg_val, avg_val)). </p>
<p>Then, we want to decide whether to fill in the pixel with black or white based on this average value. Since the RGB values are between 0 and 1, we used the value directly as a probability. According to that probability, we generated random values to determine where the pixel would be colored white. For example, if our average value was 0.1, then the pixel would have a 10% chance of being colored white. We also added an offset of 0.035 (which we found works well via experimentation) which helped bring more white spots to the rendering, which stick and poke tends to have. Finally, we used update_pixel() to add the white or black color to our sampleBuffer. </p>
<p>During the process, we experimented with a couple of other ways to achieve this effect that failed. We first tried to generalize each tile to one value and randomly color in pixels according to the corresponding probability in the RaytracedRenderer::raytrace_tile() function. However, the tiles were too large for the images to be legible since a lot of the details were abstracted away. We also tried to make these tiles smaller, but discovered that calculating probabilities based on each pixel produced the most legible results. We also tried to reveal more white parts by eliminating midtones and just making them white, but found that this created unpredictable results depending on the lighting of the original image. Adding an offset to our average worked out a lot better. </p>

<p align="middle"><b>American Traditional </b></p>
<p>American traditional tattoos try to use bold, thick outlines and stark contrast of solid black and a limited palette of bright colors (but mainly red, greens and yellows). There’s a tendency to simplify lighting, making the designs look more 2D. We can try to achieve this by reducing the complexity of the hues and shades in the mesh to the closest or desired palette color.</p>
<p> One method we used to accomplish this was by assigning our pixel color to the color in our palette that had the shortest euclidean distance from the original pixel color in our PathTracer::raytrace_pixel() function</p>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td>
                <img src="images/moreeuclidean.png" align="middle" width="400vw" />
            </td>
    </table>
</div>
<p>Since RGB Color space has three dimensions (R, G, B), its Euclidean Distance would be defined as the following:</p>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td>
                <img src="images/euclidean.png" align="middle" width="400vw" />
            </td>
    </table>
</div>
<p>The RGB value coordinates we needed were mainly bold colors of red, green, yellow, and black</p>
<p>We can further simplify the lighting, or seemingly simplify the lighting by setting the max ray depth to 1. This avoids the nuances outside of the direct lighting and provides a simple, almost “cartoonish” lighting through reduction of complexity in lighting.</p>
<p>During our attempt to implement color rendering for a tattoo design, we encountered a few problems and learned some valuable lessons. One of the biggest challenges was navigating the source code of the existing implementation for color rendering within the large codebase. This required us to spend a lot of time understanding how the code worked and how we could modify it to achieve the desired effect. Another issue we encountered was having conflicts with other artistic tattoo styles when trying to achieve a smooth integration. We had to carefully consider the color palette and ensure that it was compatible with the other styles.</p>
<p>Although this technique worked pretty well for certain images, we noticed that the results tended to be difficult to control when we used colors that were less contrastive, especially on images that were also lower contrast. To solve this problem, we decided to take the grayscale value of each pixel and separate them into five bins and then filled the pixels within each bin with its assigned shade from our chosen palette. This helped us achieve the desired effect, particularly for scenes or meshes that had less color to begin with. Overall, this project taught us the importance of carefully considering different factors when implementing color rendering for tattoo designs, such as the color palette, integration with other styles, and image quality.</p>

<p align="middle"><b>Chrome</b></p>
<p>To get the chrome effect, we kept it simple and just overlaid our outline over our rendering for the microfacet portion of project 3-2. </p>

<h2 align="middle">Results</h2>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td align="center">
                <img src="images/outlinebunny.png" align="middle" width="500vw" />
                <figcaption>Line art style bunny</figcaption>
            </td>
        </tr>
    </table>
</div>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td>
                <img src="images/stickandpokebun.png" align="middle" width="400vw" />
                <figcaption>Stick and poke style bunny</figcaption>
            </td>
            <td>
                <img src="images/stickandpokespheres.png" align="middle" width="400vw" />
                <figcaption>Stick and poke style spheres</figcaption>
            </td>
        </tr>
    </table>
</div>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td>
                <img src="images/wallenewamerican.png" align="middle" width="300vw" />
                <figcaption>New American Style Wall-E</figcaption>
            </td>
            <td>
                <img src="images/rabbitoftheeast.png" align="middle" width="300vw" />
                <figcaption>New American Style bunny</figcaption>
            </td>
            <td>
                <img src="images/stoicpeter.png" align="middle" width="300vw" />
                <figcaption>Peter with blue-purple-yellow palette. </figcaption>
            </td>
        </tr>
    </table>
</div>
<div align="middle">
    <table style="width:100%">
        <tr align="center">
            <td>
                <img src="images/chromebunny.png" align="middle" width="400vw" />
                <figcaption>Chrome style bunny</figcaption>
            </td>
            <td>
                <img src="images/chromedragon.png" align="middle" width="400vw" />
                <figcaption>Chrome style dragon</figcaption>
            </td>
        </tr>
    </table>
</div>

<h2 align="middle">References</h2>
<ul>
    <li>
        <a href="https://viterbi-web.usc.edu/~jbarbic/cs420-s22/24-npr/24-npr.pdf">Deck that goes through types of NPR</a>
    </li>
    <li><a href="https://www.researchgate.net/publication/236973460_Non-Photorealistic_Rendering">Paper that describes how to achieve various NPR techniques</a></li>
    <li>
        <a href="https://homepages.inf.ed.ac.uk/rbf/HIPR2/sobel.htm">Sobel Edge Detector</a>
    </li>
</ul>
<h2 align="middle">Contributions from each team member</h2>
<ul>
    <li>
        Jojo Chen: Implemented the stick and poke section and attempted to help debug the outline. 
    </li>
    <li>
        Michelle Chen: Helped debug the outline approach and create different palettes for the American Traditional style.
    </li>
    <li>
        Isabelle Liu: Researched and helped implement the outline approach. 
    </li>
    <li>
        Nicholas Cheng: Researched and helped implement the American traditional style. Helped debug the outline approach as well. 
    </li>
</ul>
<p>Overall, all of our members worked together and in sync throughout the entire project timeline! We are very happy with each other and our final project :)</p>
<p>Special thanks to TA Catherine Gai for looking over our checkpoint and proposal!</p>

